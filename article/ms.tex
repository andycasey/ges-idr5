%% Copyright 2016 Andrew R. Casey.  All rights reserved.

\documentclass[preprint]{aastex}

\usepackage{amsmath}
\usepackage{bm}

\IfFileExists{vc.tex}{\input{vc.tex}}{\newcommand{\githash}{UNKNOWN}\newcommand{\giturl}{UNKNOWN}}

\newcommand{\acronym}[1]{{\small{#1}}}

\newcommand{\ges}{\acronym{GES}}
\newcommand{\project}[1]{\textsl{#1}}

\newcommand{\gaiaeso}{\project{Gaia-ESO}}

\newcommand{\teff}{T_{\mathrm{eff}}}
\newcommand{\logg}{\log g}
\newcommand{\feh}{[\mathrm{Fe/H}]}
\newcommand{\normal}[2]{\mathcal{N}\left(#1, #2\right)}

\begin{document}
\title{The Gaia-ESO Survey: Combined estimates from multiple stellar analysis pipelines}

\author{
    Andrew~R.~Casey\altaffilmark{1},
   }


\begin{abstract}
  Some stuff
\end{abstract}


\keywords{stars: fundamental parameters --- stars: abundances
% Clear rest of page
\clearpage}


\section{Introduction} 
\label{sec:introduction}

% In terms of telescope time cost, GES is the largest by far.

% Huge time allocation to do heaps of cool shit.

% Analyse all spectral types

% Provides a ground-based complement to the Gaia mission.

% Huge collaboration, most of which were in-fighting previously.

% Through GES they started working together.... 

% Experts in different fields, etc.

% Multiple analysis strategy.


\section{Data}
\label{sec:data}

% Description of the setups

% Summary of the ges type and SNR of the data.

% Description of target sources included: MW, Clusters, CoRot, K2, etc.

% Blind test.

\section{Methods}
\label{sec:methods}

% Multiple analysis strategy: why

% primary advantage and disadvantage to multiple analysis strategy

% Description of two parameter rounds: stellar parameters, abundances

% What's reported by each node? Flags? Consistency of flags?

% Description of pipelines in appendix 

% Commonalities between nodes: model atmospheres, line list, normalized spectra, initial params, spectrum library, xi calibration if necessary.



% EW method and comparisons -- into an appendix?.


% What do the nodes provide? Most parameters, flags, etc.

% CONTINUE from here:
% Stellar parameter determination


% Stellar parameter homogenisation

\subsection{Flag propagation}
\label{sec:flag-propagation}

In earlier data releases the analysis nodes were \emph{encouraged} to submit flags that
describe technicalities that may have affected their analysis, or peculiar issues
that were identified in a star or spectrum.  These flags proved invaluable in enabling 
homogenisation leads to identify scenarios where particular pipelines perform poorly. 
For example, OACT (WG11) were able to identify and account for high rotation, whereas 
ULB (WG11) would not identify fast rotators, and ULB (WG11) would report significantly
noisier stellar parameters for fast rotators.


From DR5 onwards, these examples led to the decision to \emph{require} analysis nodes 
to submit stellar parameters ($\teff$, $\logg$, [Fe/H], and $\xi$ where appropriate),
for every spectrum, or supply a technical flag explaining why no stellar parameters
could be derived (preferably supply both when appropriate). The full list of flags used
in DR5 is listed in Appendix \ref{appendix:flags}.  In Figures \ref{fig:flag-propagation-wg10}
and \ref{fig:flag-propagation-wg11} we show heatmaps of flag usage between different 
analysis nodes in WG10 and WG11, respectively.  If all nodes reported the same flags then
a one-to-one density mapping would be visible.  Note that here we are only showing instances
where multiple flags have been reported for a single spectrum: for the sake of clarity we
do not show situations where only one flag is reported by a single node.  Figures 
\ref{fig:flag-propagation-wg10} and \ref{fig:flag-propagation-wg11} demonstrate that when one analysis node reports a flag, it
is highly unlikely that the same issue has been reported by another node. The most common
situation is that one node will report a descriptive flag (e.g., \texttt{10106} 
to indicate a broken spectrum containing a picket-fence or Heaviside pattern), and other
nodes will report a non-specific flag (e.g., \texttt{10302}: code convergence issue).


We constructed a sequence of rules to propagate detailed flag information to other results.
We categorised these rules to propagate to results that were derived from either the same 
spectrum (e.g., \texttt{10106} broken spectrum), or the same star (e.g., suspected binary 
star system).  These propagation rules are listed in Tables \ref{tab:flag-propagation-spectrum}
and \ref{tab:flag-propagation-cname}. Any results with propagated technical flags were 
marked as failing internally quality control standards, and were not used in the homogenisation
process.  Results with any of the flags listed in Table \ref{tab:node-specific-flags} were
were also excluded from homogenisation, however those flags were considered `node-specific'
in that they do not necessarily require propagation to other results derived from the same
spectrum or star.


We also excluded all cluster records (\texttt{GES\_TYPE} of 'XX-XX-XX' or `XX-XX-XX') 
reported by OACT (WG11).  Although OACT performed excellently in the benchmark and blind tests
in WG11, we identified convergence issues in cluster field, which consequently altered the
metallicity scale of globular clusters.

% Any other exclusions? WG10 IAC results at edges?

The total number of records (set of $\teff$, $\logg$, [Fe/H]) that were marked as failing
internal quality controls due to reported or propagated flags were XXX for WG10 and XXX for
WG11.  This represents a small fraction of the total number of records submitted in each
working group (XXX\% for WG10 and XXX\% for WG11).  The number of stars (unique \texttt{CNAME}s) where all results were excluded due to reported or propagated flags was XXX for WG10 and XXX for WG11.  These cases were principally due to data reduction issues (e.g., flags 
\texttt{10100-10150}), and these examples were supplied to the data reduction group to
examine before the sixth data release.



\subsection{Stellar parameter homogenisation}
\label{sec:stellar-parameter-homogenisation}


\noindent{}We make the following assumptions in our homogenisation model:

\begin{itemize}
    \item   \emph{The uncertainties reported by each node are incorrect.}
            This assumption is based on a cursory examination of the data:
            some nodes do not provide uncertainties in stellar parameters, and
            the uncertainties reported by some nodes could vary in percent by
            two orders of magnitude. Therefore, we assume that each node only
            provides a point estimate for astrophysical parameters.

    \item   \emph{Every node provides a biased estimate of stellar parameters.}
            We assume that every node has an unknown bias $\beta$ (offset) in each
            astrophysical parameter, 

            \begin{eqnarray}
                \mu_{true} = \mu_{node} + \beta_{node} + \epsilon
            \end{eqnarray}

            \noindent{}where $\epsilon$ represents the noise in the estimate.

    \item   \emph{The unbiased stellar parameters from any two nodes are correlated.}
            After accounting for individual node biases, we assume that the 
            stellar parameters reported by any two nodes will be correlated
            to some degree. The level of correlation between two nodes is unknown.
            This assumption arises from commonalities that led to the estimates from
            each node. Specifically: all nodes are instructed to use a common list 
            of line transitions, the same MARCS model photospheres, some nodes employ
            similar methods (e.g., spectral synthesis), and all nodes derive their 
            estimates from the same data (in some instances, even the same 
            continuum-normalized spectra are used).

            We note that even two nodes with identical methods are not guaranteed
            to be perfectly correlated, because the \emph{choice} of which transitions
            or spectral regions to use is not prescribed.

    \item   \emph{There are gaps in the data.} 
            No spectrum is guaranteed to have stellar parameters reported by all
            nodes. This assumption is a consequence of the different expertise in
            \gaiaeso: no node or method is expert across the entire range of parameter
            space explored. If stellar parameters are not reported, then the reason 
            must be specified through a \texttt{TECH} flag (see Section \ref{sec:flags}
            on flag usage).

    \item   \emph{Random uncertainties in stellar parameters will increase with
            decreasing S/N ratio.}

    \item   \emph{All `well-studied' stars have noisy measurement, and their values
            are not known with infinite precision.} But we assume they are unbiased!

    \item   \emph{The systematic uncertainty will vary across parameter space.}

    \item   \emph{All stellar parameter estimates are normally-distributed draws about 
            the true astrophysical value.}

    \item   \emph{The effective temperature $\teff$, surface gravity $\logg$, and
            metallicity $\feh$ for a single star are uncorrelated.}
            This assumption is provably incorrect, and is made for practical reasons
            only. In Section \ref{sec:scaling-the-model} we describe how the number
            of model parameters scales, and in Section \ref{sec:model-parameterisation}
            we explain how the inference problem itself is numerically unstable.
            Including correlations in stellar parameters would require a constant
            correlation term $\rho$, or modeling $\rho$ as a function of the stellar
            parameters. In either case, the number of model parameters that require
            MCMC will immediately increase by at least factor of three (e.g.,
            $\gtrsim5{,}000$ parameters), amplifying numerical stability issues and
            substantially increasing the requisite number of MCMC samples. For these
            reasons, simultaneously modeling the correlation between stellar
            parameters has been left for an extension of this work.
 
\end{itemize}

Given these assumptions the model we adopt is
\begin{eqnarray}
    \mu_{bm} = \normal{\mu_{true}}{\sigma_{bm}} 
\end{eqnarray} 


% List of the model parameters

We list the nomenclature and descriptions for all model parameters in Table 
\ref{tab:model-parameters}. The number of total model parameters is given by
\begin{eqnarray}
    N_{parameters} = N_{calibrators} + N_{missing} + 6N_{nodes} + \frac{N_{nodes}!}{2(N_{nodes} - 2)!}
\end{eqnarray}
where $N_{calibrators}$ accounts for the true values of the calibrators, the
$N_{missing}$ models the missing data points for the calibrator spectra, the
$6N_{nodes}$ summarises parameters that model biases, as well as systematic
and random uncertainties. The final term $\frac{N_{nodes}!}{2(N_{nodes} - 2)!}$
is the number of correlation coefficients between all nodes.\footnote{
This inference problem is numerically unstable because a \emph{positive semi-definite}
covariance matrix must be constructed from the model parameters in every MCMC draw, 
and there is no joint prior available to ensure that the positive semi-definite 
condition is met.  Although there are parameterisations that will help enforce 
this condition \citep{Pinheiro:1996}, in practice we found that including 
the Cholesky decomposition $L$ of the $N \times N$ correlation matrix $K$ as model
parameters --- instead of directly modelling the set of node correlation 
coefficients $\{\rho\}$ --- was sufficient to ensure positive-semidefinite 
covariance matrices and produce sensible solutions.  The correlation matrix can 
then be reconstructed by $K = (IL)\cdot(IL)^T$ where $I$ is the $N \times N$ identity
matrix.  This representation implies a uniform prior on all correlation coefficients
$p\left(\rho\right) = \mathcal{U}\left(-1, +1\right)$.}

% Priors



We implemented the model in \texttt{Stan}, a probabilistic programming
language, and the code describing our parameterisation is included as Appendix \ref{
appendix:stan-code}. We initialised the model with $\mu_{true}$ at the central
calibrator values, and set XXXXXX, with no correlation between any nodes. We
optimized all parameters in \texttt{Stan} using the Broyden-Fletcher-Goldfarb-Shanno
algorithm. The optimized point was used as an initialisation point for Markov Chain
Monte-Carlo (MCMC) sampling.

N chains, thinning, N iterations. Convergence criteria.
 
 




% Abundance determination

% Abundance homogenisation


\section{Discussion}
\label{sec:discussion}

% Is the multiple-analysis strategy justified?
% --> Take any one node, infer their uncertainties as a function of SNR using point-wise correlations (e.g., no benchmarks).
% --> What goes wrong for each node?

% Precision, accuracy, systematics.
% EW


% Analysis choices: we give same line list but not all are used.
%                   or how they are used.

 



\section{Conclusions}
\label{sec:conclusions}

% This should be a "lessons learned" list.

% The final paragraph should contain a succint forward outlook of how good or bad an idea this was.

\begin{thebibliography}{}
\bibitem[Pinheiro \& Bates(1996)]{Pinheiro:1996} Pinheiro, J.~C., \& Bates, D.~M.\ 1996, Statistics and Computing, 6, 3


\end{thebibliography}


\end{document}
